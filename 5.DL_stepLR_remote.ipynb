{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module directory 생성\n",
    "import os\n",
    "os.makedirs(\"module\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting module/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile module/train.py\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def test_binary_classification(dataloader, model, loss_fn, device=\"cpu\") -> tuple:\n",
    "    \"\"\"\n",
    "    이진 분류 검증/평가 함수\n",
    "    \n",
    "    [parameter]\n",
    "        dataloader: DataLoader - 검증할 대상 데이터로더\n",
    "        model: 검증할 모델\n",
    "        loss_fn: 모델 추정값과 정답의 차이를 계산할 loss 함수.\n",
    "        device: str - 연산을 처리할 장치. default-\"cpu\", gpu-\"cuda\"\n",
    "    [return]\n",
    "        tuple: (loss, accuracy)\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()  # 모델을 평가모드로 변환\n",
    "    size = len(dataloader.dataset)\n",
    "    num_steps = len(dataloader)\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            # 정확도 계산을 위한 예측값 비교\n",
    "            pred_label = (pred >= 0.5).type(torch.int32)\n",
    "            correct_predictions += (pred_label == y).sum().item()\n",
    "        \n",
    "        test_loss /= num_steps\n",
    "        accuracy = correct_predictions / size\n",
    "    \n",
    "    return test_loss, accuracy\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    모델을 1 epoch 학습시키는 함수\n",
    "\n",
    "    [parameter]\n",
    "        dataloader: DataLoader - 학습데이터셋을 제공하는 DataLoader\n",
    "        model - 학습대상 모델\n",
    "        loss_fn: 모델 추정값과 정답의 차이를 계산할 loss 함수.\n",
    "        optimizer - 최적화 함수\n",
    "        device: str - 연산을 처리할 장치. default-\"cpu\", gpu-\"cuda\"\n",
    "    [return]\n",
    "        float: 학습 후 계산한 Train set에 대한 train_loss\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def fit(train_loader, val_loader, model, loss_fn, optimizer, epochs, save_best_model=True, save_model_path=None, device='cpu', mode='binary', lr_scheduler=None):\n",
    "   \n",
    "    best_val_loss = float('inf') if save_best_model else None\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    model = model.to(device)\n",
    "    s = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(train_loader, model, loss_fn, optimizer, device=device)\n",
    "        \n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        # 검증 손실 평가\n",
    "        val_loss, val_accuracy = test_binary_classification(val_loader, model, loss_fn, device=device)\n",
    "\n",
    "        # 최적의 모델 저장\n",
    "        if save_best_model and val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch + 1  # 에포크는 1부터 시작하므로 +1\n",
    "            best_model_state = model.state_dict()  # 최적 모델의 가중치 저장\n",
    "            torch.save(model.state_dict(), save_model_path)\n",
    "            print(f\"Best Model 저장: Epoch {best_epoch} - Validation Loss: {best_val_loss:.5f}\")\n",
    "\n",
    "    e = time.time()\n",
    "    print(f\"총 소요 시간: {e-s:.2f}초\")\n",
    "    \n",
    "    # 최적의 모델을 로드하여 최종 성능 평가\n",
    "    model.load_state_dict(best_model_state)\n",
    "    train_loss, train_accuracy = test_binary_classification(train_loader, model, loss_fn, device=device)\n",
    "    test_loss, test_accuracy = test_binary_classification(val_loader, model, loss_fn, device=device)\n",
    "    \n",
    "    # 최적 모델 성능 출력\n",
    "    print(\"\\n최적의 체크포인트 모델:\")\n",
    "    print(f\"Best Epoch: {best_epoch}\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    return best_epoch, best_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting module/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile module/utils.py\n",
    "# 학습 결과를 시각화하는 함수.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_fit_result(train_loss_list, train_accuracy_list, valid_loss_list, valid_accuracy_list):\n",
    "    epoch = len(train_loss_list)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(epoch), train_loss_list, label=\"train loss\")\n",
    "    plt.plot(range(epoch), valid_loss_list, label=\"validation loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(epoch), train_accuracy_list, label=\"train accuracy\")\n",
    "    plt.plot(range(epoch), valid_accuracy_list, label=\"validation accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.grid(True, linestyle=':')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 40) (7043, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# X, y 데이터 분리\n",
    "X = df.drop(columns=['Churn', 'customerID']).values\n",
    "y = df['Churn'].values\n",
    "y = y.reshape(-1, 1)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# 데이터 train, test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# SMOTE 적용 (소수 클래스 샘플을 다수 클래스와 동일하게 맞춤)\n",
    "smote = SMOTE(sampling_strategy=1.0, random_state=0)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Tensor로 변환\n",
    "X_resampled = torch.tensor(X_resampled, dtype=torch.float32)\n",
    "y_resampled = torch.tensor(y_resampled, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "# TensorDataset과 DataLoader 생성\n",
    "trainset = TensorDataset(X_resampled, y_resampled)\n",
    "testset = TensorDataset(\n",
    "    torch.tensor(X_test_scaled, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.float32).view(-1,1)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset, batch_size=128)\n",
    "len(train_loader), len(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.01\n",
    "\n",
    "######### 모델 정의\n",
    "class SmallModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lr1 = nn.Linear(40, 32)\n",
    "        self.lr2 = nn.Linear(32, 8)\n",
    "        self.lr3 = nn.Linear(8, 1) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.logistic = nn.Sigmoid()  \n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.lr1(X)\n",
    "        X = self.relu(X)\n",
    "        X = self.lr2(X)\n",
    "        X = self.relu(X)\n",
    "        # 출력 Layer\n",
    "        output = self.lr3(X)\n",
    "        output = self.logistic(output)\n",
    "        return output\n",
    "        \n",
    "small_model = SmallModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(small_model.parameters(), lr=lr)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=5,\n",
    "    gamma=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model 저장: Epoch 1 - Validation Loss: 0.44345\n",
      "Best Model 저장: Epoch 4 - Validation Loss: 0.44035\n",
      "총 소요 시간: 19.48초\n",
      "\n",
      "최적의 체크포인트 모델:\n",
      "Best Epoch: 4\n",
      "====================================================================================================\n",
      "Train Loss: 0.3514, Train Accuracy: 0.8372\n",
      "Test Loss: 0.5077, Test Accuracy: 0.7480\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "from module.train import fit, test_binary_classification, train\n",
    "from module.utils import plot_fit_result\n",
    "\n",
    "# 모델 학습\n",
    "best_epoch, best_val_loss = fit(\n",
    "    train_loader, test_loader,  \n",
    "    small_model, loss_fn, optimizer,\n",
    "    epochs,\n",
    "    save_best_model=True,\n",
    "    save_model_path=\"best_model.pth\",\n",
    "    device=device,\n",
    "    mode=\"binary\",\n",
    "    lr_scheduler=lr_scheduler\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SmallModel(\n",
       "  (lr1): Linear(in_features=40, out_features=32, bias=True)\n",
       "  (lr2): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (lr3): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (logistic): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구조를 먼저 정의한 후\n",
    "model = SmallModel()  # 모델의 구조를 정의합니다.\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))  # 저장된 모델 가중치를 불러옵니다.\n",
    "model.to(device)  # GPU나 CPU로 이동\n",
    "model.eval()  # 모델을 평가 모드로 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# X, y 데이터 분리\n",
    "X = df.drop(columns=['Churn', 'customerID']).values\n",
    "y = df['Churn'].values\n",
    "y = y.reshape(-1, 1)\n",
    "X.shape, y.shape\n",
    "\n",
    "# 데이터 train, test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "trainset = TensorDataset(\n",
    "    torch.tensor(X_train_scaled, dtype=torch.float32),\n",
    "    torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "testset = TensorDataset(\n",
    "    torch.tensor(X_test_scaled, dtype=torch.float32),\n",
    "    torch.tensor(y_test, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=128, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testset, batch_size=128)\n",
    "len(train_loader), len(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, dataloader, loss_fn, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    모델을 평가하고 Confusion Matrix 및 Classification Report를 생성하는 함수\n",
    "\n",
    "    [Parameters]\n",
    "        model: nn.Module - 평가할 모델\n",
    "        dataloader: DataLoader - 평가할 데이터셋의 DataLoader\n",
    "        loss_fn: 손실 함수\n",
    "        device: str - 연산을 처리할 장치 (default: \"cpu\")\n",
    "\n",
    "    [Returns]\n",
    "        tuple: (평균 손실, 정확도, Confusion Matrix, Classification Report)\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            loss = loss_fn(outputs, y)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 이진 분류일 경우 0.5 기준으로 클래스 분류\n",
    "            pred_labels = (outputs >= 0.5).type(torch.int)\n",
    "            all_preds.extend(pred_labels.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "    \n",
    "    # 평균 손실 계산\n",
    "    avg_loss = float(total_loss / num_batches)\n",
    "    accuracy = float(sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_labels))  # 정확도를 스칼라 값으로 계산\n",
    "    \n",
    "    # Confusion Matrix와 Classification Report 생성\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, target_names=['Class 0', 'Class 1'])\n",
    "    \n",
    "    # Confusion Matrix와 Classification Report 출력\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    print(f\"\\nAverage Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return avg_loss, accuracy, cm, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[923 112]\n",
      " [177 197]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.84      0.89      0.86      1035\n",
      "     Class 1       0.64      0.53      0.58       374\n",
      "\n",
      "    accuracy                           0.79      1409\n",
      "   macro avg       0.74      0.71      0.72      1409\n",
      "weighted avg       0.79      0.79      0.79      1409\n",
      "\n",
      "\n",
      "Average Loss: 0.3997, Accuracy: 0.7949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMSUNG\\AppData\\Local\\Temp\\ipykernel_23256\\3550234096.py:39: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  accuracy = float(sum(p == l for p, l in zip(all_preds, all_labels)) / len(all_labels))  # 정확도를 스칼라 값으로 계산\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "model = SmallModel()  # 모델 구조를 다시 정의\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "# 손실 함수 정의 (예: 이진 교차 엔트로피)\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_accuracy, cm, report = evaluate_model(\n",
    "    model=model,\n",
    "    dataloader=test_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
